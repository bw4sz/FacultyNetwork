---
title: "FacultyNetworks"
author: "Ben Weinstein"
date: "Saturday, November 01, 2014"
output:
  html_document:
    toc: true
    number_sections: true
---

#Aim

Using tools from network ecology, we can begin to examine patterns of colloboration, specialization and compartamentalisation within academic departments. Using journal publications as a metric of similiarity among faculty members, we can compare the relative specialization of each department and compare academic niche breadth as a function of size, location and other measures of group interactions. I will begin with departments in Ecology and Evolution.

#Approach

1. Get list of journals with subheadings and disciplines from google to create similarity lists.
2. Get names of top academic departments in the US with a program in Ecology and Evolution.
3. Search the pubmed archives for journal title and affiliation.
4. Decompose API results into R metadata.
5. Perform network analysis on academic departments as a function of similarity in journal publications.

```{r,echo=F,warning=FALSE,message=FALSE}
#load libraries
library(XML)
library(rpubmed)
library(stringr)
library(RCurl)
library(wordcloud)
library(tm)
require(reshape)
require(sna)
require(bipartite)
require(dplyr)
require(stringr)
library(knitr)
opts_chunk$set(fig.width=10,cache=TRUE,warning=F,message=F,echo=F)
```

# List of journals and disciplines

Scrape the subcategory data from google scholar page, not the search engine, they don't allow that!
[Link](http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio)

```{r}
URLS<-c(
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_agronomycropscience",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_animalbehavior",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_animalhusbandry",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_atmosphericsciences",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_biochemistry",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_biodiversityconservationbiology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_bioinformatics",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_biophysics",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_biotechnology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_birds",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_botany",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_cellbiology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_developmentalbiologyembryology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_ecology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_environmentalgeologicalengineering",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_environmentalsciences",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_evolutionarybiology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_foodsciencetechnology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_forestsforestry",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_geochemistrymineralogy",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_geology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_hydrology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_insectsarthropods",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_biogeneral",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_marinesciencesfisheries",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_microbiology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_molecularbiology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_mycology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_oceanography",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_paleontology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_pestcontrolpesticides",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_plantpathology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_proteomicspeptides",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_soilsciences",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_sustainabledevelopment",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_sustainableenergy",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_virology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_woodsciencetechnology",
  "http://scholar.google.com/citations?view_op=top_venues&hl=en&vq=bio_zoology")


.simpleCap <- function(x) {
  s <- strsplit(x, " ")[[1]]
  paste(toupper(substring(s, 1, 1)), substring(s, 2),
        sep = "", collapse = " ")
}

#Get journal classification
out<-list()

for (x in 1:length(URLS)){
  nam<-str_match(URLS[x],"bio_(\\w+)")[2]
  xtab= readHTMLTable(URLS[x], header=T, which=1,stringsAsFactors=F)[,-1]
  out[[x]]<-data.frame(Class=.simpleCap(nam),xtab)
}

j_class<-rbind_all(out)
head(j_class)

jc<-as.data.frame(table(j_class$Class))
colnames(jc)<-c("Category","N")
kable(jc)

write.csv("j_class","Class.csv")
```

#Lists of Academic Departments

Scraping from [here](http://www.nescent.org/eog/graduateprogdatabase.php?orderby=PhD&order=asc)

125 Departments in the US.

```{r}
xtab= readHTMLTable("http://www.nescent.org/eog/graduateprogdatabase.php?orderby=PhD&order=asc", header=T, which=1,stringsAsFactors=F)[,-1]
depts<-xtab[,-c(5,6)]
kable(head(depts))
write.csv(depts,"depts.csv")
```

#Search pubmed

Let's begin slowly. I want to search an affiliation for any of the journal titles i have in my categories. I found the rpubmed package (thanks RopenSCI!!) and i want to give it a try. 
